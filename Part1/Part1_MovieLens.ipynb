{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "The goal of this personalization project will be to maximize the accuracy of our recommendation system when considering the results of recommending the top-5 movies for a given user. \n",
    "\n",
    "Max accuracy or coverage of recommendations\n",
    "\n",
    "MovieLens is a web-based recommender system and virtual community that recommends movies for its users to watch, based on their film preferences using CF of members' movie ratings and reviews. To address the cold-start problem for new users, MovieLens uses preference elicitation where they ask new users to rate how much they enjoy watching different genres of movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 10000054 ratings and 95580 tags applied to 10681 movies by 71567 users. Users were selected at random but all users selected had rated at least 20 movies. The data contains three files: \n",
    "\n",
    "#### 1. Movies.dat\n",
    "Each line of this file represents one movie, and has the following format: MovieID::Title::Genres\n",
    "MovieID is the real MovieLens id.\n",
    "\n",
    "Movie titles, by policy, should be entered identically to those found in IMDB, including year of release. However, they are entered manually, so errors and inconsistencies may exist.\n",
    "\n",
    "Genres are a pipe-separated list, and are selected from the following:\n",
    "\n",
    "Action\n",
    "Adventure\n",
    "Animation\n",
    "Children's\n",
    "Comedy\n",
    "Crime\n",
    "Documentary\n",
    "Drama\n",
    "Fantasy\n",
    "Film-Noir\n",
    "Horror\n",
    "Musical\n",
    "Mystery\n",
    "Romance\n",
    "Sci-Fi\n",
    "Thriller\n",
    "War\n",
    "Western\n",
    "\n",
    "\n",
    "#### 2. Ratings.dat\n",
    "All ratings are contained in the file ratings.dat. Each line of this file represents one rating of one movie by one user, and has the following format:\n",
    "\n",
    "UserID::MovieID::Rating::Timestamp\n",
    "\n",
    "The lines within this file are ordered first by UserID, then, within user, by MovieID.\n",
    "\n",
    "Ratings are made on a 1-5 star scale, with half-star increments.\n",
    "\n",
    "Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.\n",
    "\n",
    "\n",
    "#### 3. Tags.dat\n",
    "All tags are contained in the file tags.dat. Each line of this file represents one tag applied to one movie by one user, and has the following format:\n",
    "\n",
    "UserID::MovieID::Tag::Timestamp\n",
    "\n",
    "The lines within this file are ordered first by UserID, then, within user, by MovieID.\n",
    "\n",
    "Tags are user generated metadata about movies. Each tag is typically a single word, or short phrase. The meaning, value and purpose of a particular tag is determined by each user.\n",
    "\n",
    "Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Item-Based Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each user, we'd like to accurately recommend a set of top 5 movies they'd enjoy which they have not seen yet (their rating is 0). To do this we will use an approach that is similar to weighted KNN. \n",
    "\n",
    "The general methodology is as follows: \n",
    "1. For each movie j that user i has not seen yet, we will find a peer set P who are similar to user i, but have seen movie j. The \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will import the necessary libraries for building our item-based nearest neighbors CF model as well as read in our datasets described earlier. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "from surprise import Dataset, evaluate\n",
    "from surprise import KNNBasic\n",
    "from sklearn import cross_validation as cv\n",
    "\n",
    "\n",
    "#Define the format of each of the data files\n",
    "#Movies; MovieID::Title::Genres\n",
    "moviescol = ['MovieId', 'Title', 'Genres','Action', 'Adventure',\n",
    " 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    " 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "movies = pd.read_csv('./movies.dat', sep='::', names = moviescol, engine='python')\n",
    "\n",
    "'''\n",
    "Generates a new matrix with movie ID and indicator columns for the genre(s) of that movie.\n",
    "'''\n",
    "movie_genre = []\n",
    "for (idx, row) in movies.iterrows(): \n",
    "    genres = row.loc['Genres'].split(\"|\")\n",
    "    movieid = row.loc['MovieId']\n",
    "    for g in genres:  \n",
    "        movie_genre.append({'MovieId': movieid, 'Genre': g})\n",
    "\n",
    "#movie_genre = pd.DataFrame(moviegenre)\n",
    "\n",
    "\n",
    "moviegenrecol = ['Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'IMAX', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "test = pd.DataFrame(0, index = np.arange(len(movies)), columns = moviegenrecol)\n",
    "MovieGenres = pd.concat([movies['MovieId'], test], axis = 1)\n",
    "MovieGenres.columns= ['MovieId','Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'IMAX', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "        \n",
    "for row in movie_genre: \n",
    "    movieID = row['MovieId']\n",
    "    genre = row['Genre']\n",
    "    MovieGenres.loc[MovieGenres.MovieId==movieID,genre]=1\n",
    "\n",
    "###########################################\n",
    "# Reads in User, Item Ratings raw data file  (ratings.dat)\n",
    "###########################################\n",
    "\n",
    "#Ratings:\n",
    "#UserID::MovieID::Rating::Timestamp\n",
    "ratingscol = ['UserID', 'MovieID', 'Rating', 'Timestamp']\n",
    "ratings = pd.read_csv('./ml-10M100K/ratings.dat', sep='::', names = ratingscol, engine='python')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In order to determine the most appropriate way to sample our data, we first need to get a better understanding of the sparsity level of the user-item matrix. As seen in the introduction paper of item-based CF, we can calculate the Sparsity level of a matrix by using 1- (nonzero entries/total entries) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users = 69878 | Number of movies = 10677\n",
      "The sparsity level of MovieLens10M is 98.7%\n"
     ]
    }
   ],
   "source": [
    "# Compute the Sparsity of the Matrix by first finding the number of unique items and users present in the ratings df. Although the Movielens site already provides us with number of unique movies and usrs information, we provide a procedure to obtain it regardless.\n",
    "\n",
    "n_users = ratings['UserID'].nunique()\n",
    "n_items = ratings['MovieID'].nunique()\n",
    "\n",
    "print 'Number of users = ' + str(n_users) + ' | Number of movies = ' + str(n_items)\n",
    "\n",
    "sparsity = round(1.0-len(ratings)/float(n_users*n_items),3)\n",
    "print 'The sparsity level of MovieLens10M is ' +  str(sparsity*100) + '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we want to work with a sample size of 10000 users and 100 items to start with, we sample at random the above dataframe given all users in the original dataset provided 20 or more movie ratings. We will begin by taking .1% of our original user-movie matrix to accommodate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4514\n",
      "2158\n"
     ]
    }
   ],
   "source": [
    "ratings_subset = ratings.sample(frac = .001)\n",
    "\n",
    "print ratings_subset2['UserID'].nunique()\n",
    "print ratings_subset2['MovieID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to format the ratings matrix to be one row per user and one column per movie -- we also substitute all missing values with 0. Therefore we have a 69878 x 10677 matrix where each element of the matrix (i,j) represents how user i rated movie j. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieID  1      2      3      4      5      6      7      8      9      10     \\\n",
      "UserID                                                                          \n",
      "1          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "3          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "4          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "5          1.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0    0.0    0.0   \n",
      "\n",
      "MovieID  ...    65006  65011  65025  65027  65037  65088  65091  65126  65130  \\\n",
      "UserID   ...                                                                    \n",
      "1        ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2        ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "3        ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "4        ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "5        ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "MovieID  65133  \n",
      "UserID          \n",
      "1          0.0  \n",
      "2          0.0  \n",
      "3          0.0  \n",
      "4          0.0  \n",
      "5          0.0  \n",
      "\n",
      "[5 rows x 10677 columns]\n"
     ]
    }
   ],
   "source": [
    "ratings_pivot = ratings_subset.pivot(index = 'UserID', columns = 'MovieID', values = 'Rating').fillna(0)\n",
    "\n",
    "print ratings_pivot.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of nonzero entries in the ratings matrix is 10000054\n",
      "The sparsity of the ratings matrix is 0.986596672294\n"
     ]
    }
   ],
   "source": [
    "nonzero = np.count_nonzero(ratings_pivot)\n",
    "print 'The total number of nonzero entries in the ratings matrix is ' +  str(nonzero)\n",
    "\n",
    "totalentries = 69878*10677.0\n",
    "sparsity = 1- nonzero/totalentries\n",
    "\n",
    "print 'The sparsity of the ratings matrix is '+ str(sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having obtained a smaller working subset, we need to normalize by each user's mean. And then we can divide this normalized subset into a training and test set for our item based CF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratingsmatrix = ratings_pivot.as_matrix()\n",
    "mean_ratingsmatrix = np.mean(ratingsmatrix, axis=1)\n",
    "\n",
    "#Normalized Ratings Matrix\n",
    "Norm_RM = ratingsmatrix -mean_ratingsmatrix.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Based CF Algorithm\n",
    "Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation Methods\n",
    "\n",
    "## (i) Cross Validation Setup\n",
    "To withhold 10% of user item pairs, generate a random number for each user item pair randomly from [0,1] and withhold those >.90 for that randomly generated #\n",
    "\n",
    "\n",
    "## (ii) Accuracy on Training/Test Data\n",
    "- % Correct /Hit Rate: great for KPI correlation but they need a baseline for model accuracy otherwise it's not helpful\n",
    "- ROC - based (precision, recall, F1-score, AUC - area under curve) when building and comparing models, and communicate ROC\n",
    "- ROC  / percent-correct / hit-rate metrics when communicating to key stake holders\n",
    "\n",
    "## (iii) Coverage on training and test data\n",
    "1. Define using accuracy metrics what a good recommendation is\n",
    "2. Then \n",
    "\ta. User-Coverage: the fraction of users for which AT LEAST k items can be recommended well \n",
    "\tb. Item-Coverage: the fraction of items that can be recommended to at least k users well\n",
    "\tc. Catalog Coverage: the fraction of items that are in the top-k for at least 1 user\n",
    "    \n",
    "? What are the tradeoffs between accuracy and coverage? \n",
    "\n",
    "User bias + item bias + mean rating = baseline \n",
    "\n",
    "How do your evaluation metrics change as a function of parameters such as neighborhood size, # of latent dimensions? \n",
    "\n",
    "_Personal Note_ In general when the neighborhood size K is small, we're forcing our classifier to be \"more blind\" to the overall distribution. A small K will have low bias but higher variance. On the other hand, a higher K averages more voters in each prediction and is more resilient to outliers. This consequently results in lower variance but increased bias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Size Variation\n",
    "How does overall accuracy change when you systematically sample your data from a small to large size? How does runtime scale? \n",
    "\n",
    "a) Error vs Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
