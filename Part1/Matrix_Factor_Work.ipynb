{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priyamedberry/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "import surprise as sp\n",
    "import scipy\n",
    "from surprise import Dataset, Reader, SVD, evaluate\n",
    "from sklearn import cross_validation as cv\n",
    "from scipy import linalg\n",
    "\n",
    "\n",
    "ratingscol = ['UserID', 'MovieID', 'Rating', 'Timestamp']\n",
    "ratings = pd.read_csv('./ratings100k.dat', sep='::', names = ratingscol, engine='python')\n",
    "ratings = ratings.drop('Timestamp', axis=1)\n",
    "\n",
    "def sample(ratings, n, m):\n",
    "    \"\"\"\n",
    "    Return a smaller matrix with top n users and top m items only\n",
    "    @param ratings the ratings dataset \n",
    "    @param n number of users with most ratings\n",
    "    @param m number of movies with most ratings\n",
    "    @returns NxM matrix of USERxITEM ratings\n",
    "    \"\"\"\n",
    "\n",
    "    n_users = ratings['UserID'].nunique()\n",
    "    n_items = ratings['MovieID'].nunique()\n",
    "\n",
    "    user_sample = ratings['UserID'].value_counts().head(n).index\n",
    "    movie_sample = ratings['MovieID'].value_counts().head(m).index\n",
    "\n",
    "    subset = ratings.loc[ratings['UserID'].isin(user_sample)].loc[ratings['MovieID'].isin(movie_sample)]\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 'funcs.py'\n",
    "import surprise as sp\n",
    "from surprise import AlgoBase\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn import cross_validation as cv\n",
    "import funcs as F\n",
    "import itertools as it\n",
    "from scipy import linalg\n",
    "\n",
    "def sample(ratings, user_counts, movie_counts, n, m):\n",
    "    \"\"\"\n",
    "    Return a smaller matrix with top n users and top m items only\n",
    "    @param ratings the ratings dataset \n",
    "    @param user_counts Count values of user ratings\n",
    "    @param movie_counts Movie count values\n",
    "    @param n number of users with most ratings\n",
    "    @param m number of movies with most ratings\n",
    "    @returns NxM matrix of USERxITEM ratings\n",
    "    \"\"\"\n",
    "    n_users = ratings['UserId'].nunique()\n",
    "    n_items = ratings['MovieId'].nunique()\n",
    "\n",
    "    user_sample = user_counts.head(n).index\n",
    "    movie_sample = movie_counts.head(m).index\n",
    "\n",
    "    print len(user_sample)\n",
    "    print len(movie_sample)\n",
    "\n",
    "    subset = ratings.loc[ratings['UserId'].isin(user_sample)].loc[ratings['MovieId'].isin(movie_sample)]\n",
    "    # we don't need the timestamp\n",
    "    del subset['Timestamp']\n",
    "    return subset\n",
    "\n",
    "def normalize_user_means(ratings):\n",
    "    \"\"\"\n",
    "    @param Ratings pandas dataframe\n",
    "    @returns user mean normalized dataframe\n",
    "    \"\"\"\n",
    "    u_i_df = F.build_user_item_matrix(ratings)\n",
    "    means = u_i_df.mean(axis=1)\n",
    "\n",
    "    def f(row):\n",
    "        u_id = row[\"UserId\"]\n",
    "        new_r = row[\"Rating\"] - means[u_id]\n",
    "        return new_r\n",
    "\n",
    "    ratings['Rating'] = ratings.apply(f, axis = 1)\n",
    "    return ratings\n",
    "\n",
    "\n",
    "ratingscol = ['UserId', 'MovieId', 'Rating', 'Timestamp']\n",
    "ratings = pd.read_csv('./ratings100k.dat', sep='::', names = ratingscol, engine='python')\n",
    "ratings = ratings.drop('Timestamp', axis=1)\n",
    "ratings = normalize_user_means(ratings)\n",
    "ratings_matrix = F.build_user_item_matrix(ratings)\n",
    "ratings_matrix = ratings_matrix.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((730, 730), (730,), (6373, 6373))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def svd(matrix):\n",
    "    U, s, Vh = scipy.linalg.svd(matrix)\n",
    "    return U.shape,  s.shape, Vh.shape\n",
    "    \n",
    "svd(ratings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF():\n",
    "    \n",
    "    def __init__(self, R, k, lr, reg, iterations):\n",
    "        \"\"\"\n",
    "        Perform matrix factorization to predict empty\n",
    "        entries in a matrix.\n",
    "\n",
    "        Arguments\n",
    "        - R (ndarray)   : user-item rating matrix\n",
    "        - K (int)       : number of latent factors\n",
    "        - lr (float) : learning rate\n",
    "        - reg (float)  : regularization parameter\n",
    "        \"\"\"\n",
    "\n",
    "        self.R = R\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.k = k\n",
    "        self.lr = lr\n",
    "        self.reg = reg\n",
    "        self.iterations = iterations\n",
    "        \n",
    "    def train(self):\n",
    "        # Initialize user and item latent feature matrice\n",
    "        # P is a k x n matrix(n = number of users)\n",
    "        # Q is a m x k matrix(m = number of items)\n",
    "        self.P = np.random.normal(scale=1./self.k, size=(self.num_users, self.k))\n",
    "        self.Q = np.random.normal(scale=1./self.k, size=(self.num_items, self.k))\n",
    "\n",
    "        # Initialize the user/item biases\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_items)\n",
    "\n",
    "        # Don't include ratings of 0 into mean because those items are unrated\n",
    "        self.b = np.mean(self.R[np.where(self.R != 0)])\n",
    "\n",
    "        # Create a list of training samples\n",
    "        self.samples = [\n",
    "            (i, j, self.R[i, j])\n",
    "            for i in range(self.num_users)\n",
    "            for j in range(self.num_items)\n",
    "            if self.R[i, j] > 0\n",
    "            ]\n",
    "\n",
    "        # Perform stochastic gradient descent for number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            mse = self.mse()\n",
    "            training_process.append((i, mse))\n",
    "            if (i+1) % 1 == 0:\n",
    "                print(\"Iteration: %d ; error = %.4f\" % (i+1, mse))\n",
    "\n",
    "        return training_process\n",
    "\n",
    "    def sgd(self):\n",
    "        \"\"\"\n",
    "        Perform stochastic gradient descent\n",
    "        \"\"\"\n",
    "        for i, j, r in self.samples:\n",
    "            # Computer prediction and error\n",
    "            # i = user index, j = item index, r = preexisting rating\n",
    "            prediction = self.get_rating(i, j)\n",
    "            err = (r - prediction)\n",
    "\n",
    "            # Update biases\n",
    "            self.b_u[i] += self.lr * (err - self.reg * self.b_u[i])\n",
    "            self.b_i[j] += self.lr * (err - self.reg * self.b_i[j])\n",
    "\n",
    "            # Update user and item latent feature matrices\n",
    "            self.P[i, :] += self.lr * (err * self.Q[j, :] - self.reg * self.P[i,:])\n",
    "            self.Q[j, :] += self.lr * (err * self.P[i, :] - self.reg * self.Q[j,:])\n",
    "\n",
    "    def get_rating(self, i, j):\n",
    "        \"\"\"\n",
    "        Get the predicted rating of user i and item j\n",
    "        \"\"\"\n",
    "        prediction = self.b + self.b_u[i] + self.b_i[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "    \n",
    "    def mse(self):\n",
    "        \"\"\"\n",
    "        A function to compute the total mean square error\n",
    "        \"\"\"\n",
    "        xs, ys = self.R.nonzero()\n",
    "        predicted = self.full_matrix()\n",
    "        error = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            error += pow(self.R[x, y] - predicted[x, y], 2)\n",
    "        error = error/np.count_nonzero(self.R)\n",
    "        return np.sqrt(error)\n",
    "\n",
    "    def full_matrix(self):\n",
    "        \"\"\"\n",
    "        Compute the full matrix using the resultant biases, P and Q\n",
    "        \"\"\"\n",
    "        return mf.b + mf.b_u[:,np.newaxis] + mf.b_i[np.newaxis:,] + mf.P.dot(mf.Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 ; error = 0.9240\n",
      "Iteration: 2 ; error = 0.8966\n",
      "Iteration: 3 ; error = 0.8828\n",
      "Iteration: 4 ; error = 0.8736\n",
      "Iteration: 5 ; error = 0.8668\n",
      "Iteration: 6 ; error = 0.8616\n",
      "Iteration: 7 ; error = 0.8570\n",
      "Iteration: 8 ; error = 0.8533\n",
      "Iteration: 9 ; error = 0.8499\n",
      "Iteration: 10 ; error = 0.8471\n",
      "Iteration: 11 ; error = 0.8444\n",
      "Iteration: 12 ; error = 0.8419\n",
      "Iteration: 13 ; error = 0.8397\n",
      "Iteration: 14 ; error = 0.8374\n",
      "Iteration: 15 ; error = 0.8351\n",
      "Iteration: 16 ; error = 0.8328\n",
      "Iteration: 17 ; error = 0.8304\n",
      "Iteration: 18 ; error = 0.8278\n",
      "Iteration: 19 ; error = 0.8250\n",
      "Iteration: 20 ; error = 0.8221\n",
      "Iteration: 21 ; error = 0.8186\n",
      "Iteration: 22 ; error = 0.8146\n",
      "Iteration: 23 ; error = 0.8101\n",
      "Iteration: 24 ; error = 0.8052\n",
      "Iteration: 25 ; error = 0.7996\n",
      "Iteration: 26 ; error = 0.7934\n",
      "Iteration: 27 ; error = 0.7868\n",
      "Iteration: 28 ; error = 0.7796\n",
      "Iteration: 29 ; error = 0.7722\n",
      "Iteration: 30 ; error = 0.7643\n",
      "Iteration: 31 ; error = 0.7562\n",
      "Iteration: 32 ; error = 0.7479\n",
      "Iteration: 33 ; error = 0.7393\n",
      "Iteration: 34 ; error = 0.7306\n",
      "Iteration: 35 ; error = 0.7217\n",
      "Iteration: 36 ; error = 0.7127\n",
      "Iteration: 37 ; error = 0.7035\n",
      "Iteration: 38 ; error = 0.6942\n",
      "Iteration: 39 ; error = 0.6850\n",
      "Iteration: 40 ; error = 0.6757\n",
      "Iteration: 41 ; error = 0.6663\n",
      "Iteration: 42 ; error = 0.6569\n",
      "Iteration: 43 ; error = 0.6477\n",
      "Iteration: 44 ; error = 0.6385\n",
      "Iteration: 45 ; error = 0.6294\n",
      "Iteration: 46 ; error = 0.6204\n",
      "Iteration: 47 ; error = 0.6114\n",
      "Iteration: 48 ; error = 0.6026\n",
      "Iteration: 49 ; error = 0.5940\n",
      "Iteration: 50 ; error = 0.5854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.92395593525316222),\n",
       " (1, 0.89659636004759691),\n",
       " (2, 0.88276115229152685),\n",
       " (3, 0.87355977563968434),\n",
       " (4, 0.86675428379635555),\n",
       " (5, 0.86156965717716893),\n",
       " (6, 0.85700386491259906),\n",
       " (7, 0.85329696072338235),\n",
       " (8, 0.84991729085037526),\n",
       " (9, 0.84708518920789699),\n",
       " (10, 0.84437319983672421),\n",
       " (11, 0.84194408504496399),\n",
       " (12, 0.83970041526244532),\n",
       " (13, 0.83736200373750957),\n",
       " (14, 0.83513256607418529),\n",
       " (15, 0.83279649727022687),\n",
       " (16, 0.83044011637848481),\n",
       " (17, 0.82783102047263313),\n",
       " (18, 0.82502252730261005),\n",
       " (19, 0.82205759504139797),\n",
       " (20, 0.81859884543792272),\n",
       " (21, 0.81455575584524975),\n",
       " (22, 0.81012706402438583),\n",
       " (23, 0.80521301087670061),\n",
       " (24, 0.79955036438483773),\n",
       " (25, 0.7933848512811239),\n",
       " (26, 0.78680848413499926),\n",
       " (27, 0.77964500673498849),\n",
       " (28, 0.77215945797084784),\n",
       " (29, 0.76430445246944634),\n",
       " (30, 0.75617049455666707),\n",
       " (31, 0.7478541619401855),\n",
       " (32, 0.73930810476296716),\n",
       " (33, 0.73063164894876853),\n",
       " (34, 0.72167397717389947),\n",
       " (35, 0.71267454782383843),\n",
       " (36, 0.70347727410270355),\n",
       " (37, 0.69424679557572355),\n",
       " (38, 0.68496985801881527),\n",
       " (39, 0.67565220361768907),\n",
       " (40, 0.66626508348746671),\n",
       " (41, 0.6569300301576011),\n",
       " (42, 0.64769976142931129),\n",
       " (43, 0.63845719129583645),\n",
       " (44, 0.62937192800551922),\n",
       " (45, 0.62039875375119047),\n",
       " (46, 0.61136332773244106),\n",
       " (47, 0.60259342254040815),\n",
       " (48, 0.59401604986741197),\n",
       " (49, 0.5854257469220947)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf = MF(ratings_matrix, k=50, lr=0.005, reg=0.02, iterations=50)\n",
    "mf.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_matrix(ratings, factor):\n",
    "    \"\"\"\n",
    "    Train a model and return it. Then we can use the model and evaluate it elsewhere\n",
    "    @param ratings dataframe pandas dataframe to train on, with columns UserId, MovieId, Ratings\n",
    "    @param n_folds number of folds for cross validation\n",
    "    @returns List of (algo, test data)\n",
    "    We can call methods such as `test` and `evaluate` on this object \n",
    "    \"\"\"\n",
    "\n",
    "    train_data, test_data = cv.train_test_split(ratings, test_size = 0.20)\n",
    "    reader = sp.Reader(rating_scale=(1, 5))\n",
    "\n",
    "    trainset = sp.Dataset.load_from_df(train_data, reader)\n",
    "    testset = sp.Dataset.load_from_df(test_data, reader)\n",
    "    trainset.split(n_folds = 5)\n",
    "\n",
    "    algo = sp.SVD(n_factors = factor)\n",
    "\n",
    "    for trainset, _ in trainset.folds():\n",
    "        algo.train(trainset)\n",
    "        \n",
    "    testset = testset.build_full_trainset().build_testset()\n",
    "    return (algo, testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_predictions_by_user(predictions):\n",
    "    \"\"\"\n",
    "    @param List of Surprise predictions objects\n",
    "    @returns Dict {uid: [P1, P2, ...PN]} hash mapping user id to top n predictions\n",
    "    \"\"\"\n",
    "    p = sorted(predictions, key = lambda x: x.uid)\n",
    "\n",
    "    groups = {}\n",
    "    for k, g in it.groupby(p, lambda x: x.uid):\n",
    "        groups[k] = sorted(list(g), key = lambda x: x.est, reverse = True)\n",
    "\n",
    "    return groups\n",
    "\n",
    "\n",
    "# For every item that a user would be rated, in top k\n",
    "def calculate_catalog_coverage(ratings, predictions, k):\n",
    "    \"\"\"\n",
    "    Calculate the catalog coverage of a model over a dataset\n",
    "    @param ratings pandas dataframe with UserId, MovieId, Ratings. Must be the same set the model was trained on\n",
    "    @param List Surprise predictions\n",
    "    @oaram k Int the top k recommendations size\n",
    "    @returns Float percentage of items recommended to at least one user\n",
    "    \"\"\"\n",
    "    n_movies = ratings['MovieId'].nunique()\n",
    "\n",
    "    movies_reccommended = set() # keep track of which movies are recommended. Note we only care about the number\n",
    "\n",
    "    recommendations = group_predictions_by_user(predictions)\n",
    "    for u_id, recs in recommendations.iteritems():\n",
    "        movies_reccommended.update(map(lambda x: x.iid, recs[0:3]))\n",
    "\n",
    "    return len(movies_reccommended) / float(n_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(algo, ratings, testset, top_k):\n",
    "    \"\"\"\n",
    "    @param algo Surprise algorithm the model that was trained\n",
    "    @oaram ratings The ratings it was trained on, in pandas Dataframe form (so we can calculate coverage)\n",
    "    @param testset Surprise testset object, the data held out during cross-validation\n",
    "    @returns Nested Dictionary {test: {rmse, mae}, train: {rmse, mae, cc}}\n",
    "    We can use these to build up arrays for plotting.\n",
    "    \"\"\"\n",
    "\n",
    "    ret = {}\n",
    "    ret['test'] = {}\n",
    "    ret['train'] = {}\n",
    "\n",
    "    test_predictions = algo.test(testset)\n",
    "    # see how it would do on the trainset to compare, comes with the algo object\n",
    "    trainset = algo.trainset.build_testset()\n",
    "    train_predictions = algo.test(trainset)\n",
    "\n",
    "    # sticking evaluate in everything for grep, training is verbose\n",
    "    ret['test']['rmse'] = sp.accuracy.rmse(test_predictions)\n",
    "    ret['train']['rmse'] = sp.accuracy.rmse(train_predictions)\n",
    "\n",
    "    ret['test']['mae'] = sp.accuracy.mae(test_predictions)\n",
    "    ret['train']['mae'] = sp.accuracy.mae(train_predictions)\n",
    "\n",
    "    # Hackish, baseline does not have a sense of \"neighbors\"\n",
    "    if (algo.__module__ == \"surprise.prediction_algorithms.knns\"):\n",
    "        ret['test']['cc'] = calculate_catalog_coverage(ratings, test_predictions, top_k)\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MF with f of 5\n",
      "RMSE: 0.8913\n",
      "RMSE: 0.7613\n",
      "MAE:  0.6980\n",
      "MAE:  0.5935\n",
      "Evaluating MF with f of 10\n",
      "RMSE: 0.8181\n",
      "RMSE: 0.7762\n",
      "MAE:  0.6593\n",
      "MAE:  0.6065\n",
      "Evaluating MF with f of 20\n",
      "RMSE: 0.8875\n",
      "RMSE: 0.7449\n",
      "MAE:  0.6809\n",
      "MAE:  0.5851\n",
      "Evaluating MF with f of 40\n",
      "RMSE: 0.8224\n",
      "RMSE: 0.7292\n",
      "MAE:  0.6640\n",
      "MAE:  0.5719\n",
      "Evaluating MF with f of 50\n",
      "RMSE: 0.8981\n",
      "RMSE: 0.7027\n",
      "MAE:  0.7031\n",
      "MAE:  0.5516\n",
      "Evaluating MF with f of 75\n",
      "RMSE: 0.9062\n",
      "RMSE: 0.6469\n",
      "MAE:  0.6933\n",
      "MAE:  0.5098\n",
      "Evaluating MF with f of 5\n",
      "RMSE: 0.8463\n",
      "RMSE: 0.7787\n",
      "MAE:  0.6609\n",
      "MAE:  0.6074\n",
      "Evaluating MF with f of 10\n",
      "RMSE: 0.8495\n",
      "RMSE: 0.7635\n",
      "MAE:  0.6596\n",
      "MAE:  0.5983\n",
      "Evaluating MF with f of 20\n",
      "RMSE: 0.8384\n",
      "RMSE: 0.7609\n",
      "MAE:  0.6531\n",
      "MAE:  0.5942\n",
      "Evaluating MF with f of 40\n",
      "RMSE: 0.8476\n",
      "RMSE: 0.7268\n",
      "MAE:  0.6625\n",
      "MAE:  0.5658\n",
      "Evaluating MF with f of 50\n",
      "RMSE: 0.8664\n",
      "RMSE: 0.7033\n",
      "MAE:  0.6809\n",
      "MAE:  0.5475\n",
      "Evaluating MF with f of 75\n",
      "RMSE: 0.8519\n",
      "RMSE: 0.6598\n",
      "MAE:  0.6638\n",
      "MAE:  0.5152\n",
      "Evaluating MF with f of 5\n",
      "RMSE: 0.8515\n",
      "RMSE: 0.7945\n",
      "MAE:  0.6634\n",
      "MAE:  0.6178\n",
      "Evaluating MF with f of 10\n",
      "RMSE: 0.8410\n",
      "RMSE: 0.7872\n",
      "MAE:  0.6494\n",
      "MAE:  0.6135\n",
      "Evaluating MF with f of 20\n",
      "RMSE: 0.8573\n",
      "RMSE: 0.7607\n",
      "MAE:  0.6581\n",
      "MAE:  0.5927\n",
      "Evaluating MF with f of 40\n",
      "RMSE: 0.8399\n",
      "RMSE: 0.7285\n",
      "MAE:  0.6601\n",
      "MAE:  0.5642\n",
      "Evaluating MF with f of 50\n",
      "RMSE: 0.8532\n",
      "RMSE: 0.7109\n",
      "MAE:  0.6641\n",
      "MAE:  0.5536\n",
      "Evaluating MF with f of 75\n",
      "RMSE: 0.8485\n",
      "RMSE: 0.6736\n",
      "MAE:  0.6586\n",
      "MAE:  0.5248\n",
      "Evaluating MF with f of 5\n",
      "RMSE: 0.8286\n",
      "RMSE: 0.8002\n",
      "MAE:  0.6459\n",
      "MAE:  0.6217\n",
      "Evaluating MF with f of 10\n",
      "RMSE: 0.8469\n",
      "RMSE: 0.7920\n",
      "MAE:  0.6552\n",
      "MAE:  0.6151\n",
      "Evaluating MF with f of 20\n",
      "RMSE: 0.8266\n",
      "RMSE: 0.7711\n",
      "MAE:  0.6470\n",
      "MAE:  0.5972\n",
      "Evaluating MF with f of 40\n",
      "RMSE: 0.8311\n",
      "RMSE: 0.7357\n",
      "MAE:  0.6465\n",
      "MAE:  0.5720\n",
      "Evaluating MF with f of 50\n",
      "RMSE: 0.8527\n",
      "RMSE: 0.7191\n",
      "MAE:  0.6642\n",
      "MAE:  0.5580\n",
      "Evaluating MF with f of 75\n",
      "RMSE: 0.8435\n",
      "RMSE: 0.6811\n",
      "MAE:  0.6525\n",
      "MAE:  0.5300\n"
     ]
    }
   ],
   "source": [
    "# run models with some different parameters and sizes\n",
    "# samples = [ [1000, 10], [5000, 50], [100000, 1000], [5000000, 2000] ]\n",
    "samples = [ [1000, 10], [5000, 50], [10000,100], [20000,200] ]\n",
    "factors = [5, 10, 20, 40, 50, 75]\n",
    "\n",
    "for _sample in samples:\n",
    "    i, j = _sample\n",
    "    _dataset = sample(ratings, i, j)\n",
    "    for f in factors:\n",
    "        MF, MF_test = train_matrix(_dataset, f)\n",
    "\n",
    "        print \"Evaluating MF with f of {}\".format(f)\n",
    "        evaluate(MF, _dataset, MF_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
